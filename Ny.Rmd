---
title: "Ny"
author: '1'
date: "2025-09-28"
output: html_document
---
```{r}
library("car")
library("lmtest")
baltic_data <- read.csv("baltic_DIN.csv")
str(baltic_data)
```
Ser att endast x20 är ej numerisk och kategorisk. 
Gör därför om denna till en faktor så att R sedan automatiskt dummykodar den vid körning av lm(). 
```{r}
baltic_data$x20 <- as.factor(baltic_data$x20)
# Sätter Sverige som referens.
baltic_data$x20 <- relevel(baltic_data$x20, ref = "SWEDEN")
```

Börjar undersöka datan, kollar skewness.
```{r}
hist(baltic_data$y)
```
Ser att histogrammet är starkt höger-skev, alltså ett fåtal väldigt stora värden. Logaritmeting av y ger en mer symmterisk fördelning genom att dämpa stora värden och kan förbättra regressionsmodell.

Börjar dock med en full modell helt orörd.
```{r}
full_model <- lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 + 
                     x12 + x13 + x14 + x15 + x16 + x17 + x18 + x19 +x20, 
                     data = baltic_data)
```

Undersöker modellen med diagnostiska plottar.
```{r}
par(mfrow = c(2, 2))
plot(full_model)
```
Ganska klar normalfördelning av residualerna visar QQ-plotten, däremot är Residuals vs Fitted och Scale-Location lite mer svårtolkade men hintar om ev. heteroskedasticitet samt icke-linjäritet. Provar därför att logaritmera y, vilket kan korrigera dessa.

```{r}
logy_model <- lm(log(y) ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 + 
                     x12 + x13 + x14 + x15 + x16 + x17 + x18 + x19 +x20, 
                     data = baltic_data)
```
```{r}
par(mfrow = c(2, 2))
plot(logy_model)
```
Samtliga grafer förbättrades, liknar någorlunda slumpmoln i både Residual vs Fitted samt Scale-Location. Plottarna tyder på att modellantagandena homoskedasticitet, icke-linjäritet samt normalfördelade residualer ser ut att vara uppfyllda för modellen.

Går nu vidare i analysen och undersöker om det även kan vara rimligt att transformera vissa av de förklarande variablerna för att få så rättvisande modell som möjligt innan ev variabler börjar plockas bort. Plottar parvis alla förklarande variabler mot y.
```{r}
res <- residuals(logy_model)
png("residual_plots.png", width = 1600, height = 1200)

par(mfrow = c(4, 5))
for (var in paste0("x", 1:19)){
  plot(baltic_data[[var]], res,  
       main = paste("Residualer vs", var), 
       xlab = var, ylab = "Residualer")
  abline(h = 0, col = "red", lty = 2)
}

dev.off()
```
Från plottarna så ser man att samtliga utom x3, x4, x16 och x19 är klart högerskeva och då kandidater för log.


Eftersom x3 och x4 är perfekt kolineära (adderar till 100) så tar jag bort x4.
```{r}
logy_model_no_x4 <- update(logy_model, .~. - x4)
```

Log-transformerar x1 och kollar plot.
```{r}
baltic_data$logx1 <- log(baltic_data$x1)
logy_model_no_x4_logx1 <- update(logy_model_no_x4, .~. -x1 + logx1)
```
```{r}
resx1 <- residuals(logy_model_no_x4_logx1)
png("residual_plots_logx1.png", width = 1600, height = 1200)

  plot(baltic_data$logx1, resx1,  
       main = paste("Residualer vs logx1"), 
       xlab = "logx1", ylab = "Residualer")
  abline(h = 0, col = "red", lty = 2)

dev.off()
```
Plotten ser mycket bättre ut, jämnare fördelningar med x1 och logx1.

Jämför modeller:
```{r}
summary(logy_model_no_x4)
summary(logy_model_no_x4_logx1)
AIC(logy_model_no_x4)
AIC(logy_model_no_x4_logx1)
```
Fick klart bättre värden efter att logaritmerat x1. Residual standard error gick från 0.907 till 0.747, R^2 från 0.750 till 0.830 och AIC från 301.6 till 260.8.

Fortsätter med att testa log-transformera x2 och jämför mot modellen med x2.
```{r}
baltic_data$logx2 <- log(baltic_data$x2)
logy_model_no_x4_logx1_x2 <- update(logy_model_no_x4_logx1, .~. - x2 + logx2)
summary(logy_model_no_x4_logx1)
summary(logy_model_no_x4_logx1_x2)
AIC(logy_model_no_x4_logx1)
AIC(logy_model_no_x4_logx1_x2)
```
Kollar histogrammen för de förklarande variablerna.
```{r}
vars_to_check <- c("x3", "x5", "x6", "x7", "x8", "x9", "x10", "x11", "x12", "x13", "x14", "x15", "x16", "x17", "x18")
par(mfrow = c(3, 5))
for (v in vars_to_check) {
  hist(baltic_data[[v]], main = v, xlab = v)
}

```
Samtliga utom x3 och x16 högerskev, stämmer med tidigare scatter plots, fortsätter med logaritmering av x5-x15 samt x17 och x18, samt skapar min nya logaritmerade modell där x4 är borttagen, och endast x3, x16, x19 och x20 ej är logaritmerade.

```{r}
vars_to_log <- c(paste0("x", 5:15), "x17", "x18")

for (v in vars_to_log) {
  baltic_data[[paste0("log", v)]] <- log1p(baltic_data[[v]])
}
```
```{r}
log_full_model_no_x4 <- lm(log(y) ~ logx1 + logx2 + x3 + logx5 + logx6 + logx7 + logx8 + logx9 + logx10 + logx11 +
    logx12 + logx13 + logx14 + logx15 + x16 + logx17 + logx18 + x19 + x20, data = baltic_data)
```

Jämför nu denna modell med min hittills bästa:
```{r}
summary(log_full_model_no_x4)
summary(logy_model_no_x4_logx1_x2)
AIC(log_full_model_no_x4)
AIC(logy_model_no_x4_logx1_x2)
vif(log_full_model_no_x4)
vif(logy_model_no_x4_logx1_x2)
```
Klart bättre värden på residual standard error 0.4457, R^2 0.9395 och AIC 187.48, däremot visar vif en hel del multipel kolinearitet som nu behöver jobbas vidare med.

Kan vara värt att kolla prediktionsförmågan på min nu logaritmerade modell, innan borttagande av variabler. Avlägsnar dock Litauen som endast har 1 observation eftersom 1 observation skapar problem med test och träningsdatan i LOOCV, 1 observation har inget större inflytande på DIN i sin helhet över hela Östersjöområdet.
```{r}
baltic_data_no_LITHUANIA <- subset(baltic_data, x20 != "LITHUANIA")
```
```{r}
n <- nrow(baltic_data_no_LITHUANIA)
sep <- numeric(n)

for (i in 1:n) {
  train_data <- baltic_data_no_LITHUANIA[-i, ]
  test_data  <- baltic_data_no_LITHUANIA[i, , drop = FALSE]
  
  # Fit model to training data
  model_i <- lm(log(y) ~ logx1 + logx2 + x3 + logx5 + logx6 + logx7 + 
                  logx8 + logx9 + logx10 + logx11 + logx12 + logx13 + 
                  logx14 + logx15 + x16 + logx17 + logx18 + x19 + x20,
                data = train_data)
  
  # Predict and back-transform to original scale
  pred_log_y <- predict(model_i, newdata = test_data)
  pred_y <- exp(pred_log_y)
  
  # Store squared error
  sep[i] <- (test_data$y - pred_y)^2
}

# Calculate RMSEP
loocv_rmsep <- sqrt(mean(sep))
cat("LOOCV-RMSEP:", loocv_rmsep, "\n")

# Standard deviation of actual y values (to compare relative error)
cat("Genomsnittliga prediktionsfelet:", sd(baltic_data$y), "\n")
```
LOOCV-RMSEP: 3101.058 SD of y: 10593.71 -> felet i prediktionerna är ca 29% av standardavvikelsen för y, vilket ses som ett bra värde för prediktion. Nu har vi en prediktionsmodell att jämföra framtida förenklade modeller med.

För att jobba vidare med modellen och förbättra dess tolkning och förklaringsstyrka så behöver vi minska vif-värden, alltså minska multikolineariteten. Eftersom x1 är summan av x6 till x15 (totala arean) så finns här perfekt multikolinearitet och därav väljer jag att ta bort x6-x15. Eller logx6 till logx15 i detta fall.
```{r}
log_full_model_no_x4_x6_to_x15 <- update(log_full_model_no_x4, .~. -(logx6 + logx7 + 
                  logx8 + logx9 + logx10 + logx11 + logx12 + logx13 + 
                  logx14 + logx15))
summary(log_full_model_no_x4_x6_to_x15)
AIC(log_full_model_no_x4_x6_to_x15)
vif(log_full_model_no_x4_x6_to_x15)
```
Provar step-funktionen istället:
```{r}
log_full_model_no_x4_step <- step(log_full_model_no_x4, direction = "both")
vif(log_full_model_no_x4_step)
summary(log_full_model_no_x4_step)
```

```{r}
baltic_data$total_log_livestock <- baltic_data$logx17 + baltic_data$logx18
log_full_model_no_x4_step_total_log_livestock <- lm(log(y) ~logx2 + x3 + logx7 + logx8 + logx9 + logx11 + 
    x16 + total_log_livestock + x19 + x20, data = baltic_data)
summary(log_full_model_no_x4_step_total_log_livestock)
AIC(log_full_model_no_x4_step_total_log_livestock)
vif(log_full_model_no_x4_step_total_log_livestock)
```

```{r}
log_full_model_no_x4_livestock <- update(log_full_model_no_x4, .~. - logx17 - logx18 + total_log_livestock)
summary(log_full_model_no_x4_livestock)
AIC(log_full_model_no_x4_livestock)
vif(log_full_model_no_x4_livestock)
```

```{r}
subjektiv_modell <- update(log_full_model_no_x4_livestock, .~. - logx1 - logx2)
summary(subjektiv_modell)
AIC(subjektiv_modell)
vif(subjektiv_modell)
```

```{r}
subjektiv_modell_1 <- update(subjektiv_modell, .~. - logx11)
summary(subjektiv_modell_1)
AIC(subjektiv_modell_1)
vif(subjektiv_modell_1)
```

```{r}
baltic_data$log_andel_skog <- baltic_data$logx6 + baltic_data$logx7 + baltic_data$logx8 + baltic_data$logx9
subjektiv_modell_2 <- update(subjektiv_modell, .~. - logx11 - logx6 - logx7 - logx8 - logx9 + log_andel_skog)
summary(subjektiv_modell_2)
AIC(subjektiv_modell_2)
vif(subjektiv_modell_2)
```

```{r}
cor(baltic_data[, c("x3", "logx5", "log_andel_skog", "logx9", "logx10", "logx12", "logx13", "logx14", "logx15", "x16", "total_log_livestock", "x19")], use = "complete.obs")
```


```{r}
log_full_model_no_x4_to_x15 <- update(log_full_model_no_x4_x6_to_x15, .~. - logx5)
summary(log_full_model_no_x4_to_x15)
AIC(log_full_model_no_x4_to_x15)
vif(log_full_model_no_x4_to_x15)
```

```{r}
log_full_model_no_x4_to_x15_livestock <- update(log_full_model_no_x4_x6_to_x15, .~. - logx5 - logx17 - logx18 + total_log_livestock)
summary(log_full_model_no_x4_to_x15_livestock)
AIC(log_full_model_no_x4_to_x15_livestock)
vif(log_full_model_no_x4_to_x15_livestock)
```

```{r}
log_full_model_no_x2_x4_or_x6_to_x15_livestock <- update(log_full_model_no_x4_x6_to_x15, .~. - logx2 - logx17 - logx18 + total_log_livestock)
summary(log_full_model_no_x2_x4_or_x6_to_x15_livestock)
AIC(log_full_model_no_x2_x4_or_x6_to_x15_livestock)
vif(log_full_model_no_x2_x4_or_x6_to_x15_livestock)
```

```{r}
baltic_data_no_LITHUANIA <- subset(baltic_data, x20 != "LITHUANIA")
```
```{r}
n <- nrow(baltic_data_no_LITHUANIA)
sep <- numeric(n)

for (i in 1:n) {
  train_data <- baltic_data_no_LITHUANIA[-i, ]
  test_data  <- baltic_data_no_LITHUANIA[i, , drop = FALSE]
  
  # Fit model to training data
  model_i <- lm(log(y) ~ logx1 + logx2 + x3 + x16 + x19 + x20 + 
                  total_log_livestock, data = train_data)
  
  # Predict and back-transform to original scale
  pred_log_y <- predict(model_i, newdata = test_data)
  pred_y <- exp(pred_log_y)
  
  # Store squared error
  sep[i] <- (test_data$y - pred_y)^2
}

# Calculate RMSEP
loocv_rmsep <- sqrt(mean(sep))
cat("LOOCV-RMSEP:", loocv_rmsep, "\n")

# Standard deviation of actual y values (to compare relative error)
cat("Standardavvikelse för y:", sd(baltic_data$y), "\n")

# Relativt prediktionsfel
rel_pred <- loocv_rmsep / sd(baltic_data$y)
print(paste("Relativt prediktionsfel:", rel_pred))
```